# Configuration files that customize the default behaviour of non-linear searches.

# **PyAutoFit** supports the following maximum likelihood estimator (MLE) algorithms:

# - PySwarms: https://github.com/ljvmiranda921/pyswarms / https://pyswarms.readthedocs.io/en/latest/index.html

# Settings in the [search], [run] and [options] entries are specific to each nested algorithm and should be
# determined by consulting that method's own readthedocs.

PySwarmsGlobal:
  run:
    iters: 2000
  search:
    cognitive: 0.5
    ftol: -.inf
    inertia: 0.9
    n_particles: 50
    social: 0.3
  initialize:                       # The method used to generate where walkers are initialized in parameter space {prior | ball}.
    method: ball                    # priors: samples are initialized by randomly drawing from each parameter's prior. ball: samples are initialized by randomly drawing unit values from a narrow uniform distribution.
    ball_lower_limit: 0.49          # The lower limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
    ball_upper_limit: 0.51          # The upper limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
  parallel:
    number_of_cores: 1              # The number of cores the search is parallelized over by default, using Python multiprocessing.
  printing:
    silence: false                  # If True, the default print output of the non-linear search is silcened and not printed by the Python interpreter.
    iterations_per_full_update: 500      # Non-linear search iterations between every full update, which outputs all visuals and result fits (e.g. model.result, search.summary), this exits the search and can be slow.
    iterations_per_quick_update: 500 #  Non-linear search iterations between every quick update, which just displays the maximum likelihood model fit.
    remove_state_files_at_end: true # Whether to remove the savestate of the seach (e.g. the Emcee hdf5 file) at the end to save hard-disk space (results are still stored as PyAutoFit pickles and loadable).
PySwarmsLocal:
  run:
    iters: 2000
  search:
    cognitive: 0.5
    ftol: -.inf
    inertia: 0.9
    minkowski_p_norm: 2
    n_particles: 50
    number_of_k_neighbors: 3
    social: 0.3
  initialize:                       # The method used to generate where walkers are initialized in parameter space {prior | ball}.
    method: ball                    # priors: samples are initialized by randomly drawing from each parameter's prior. ball: samples are initialized by randomly drawing unit values from a narrow uniform distribution.
    ball_lower_limit: 0.49          # The lower limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
    ball_upper_limit: 0.51          # The upper limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
  parallel:
    number_of_cores: 1              # The number of cores the search is parallelized over by default, using Python multiprocessing.
  printing:
    silence: false                  # If True, the default print output of the non-linear search is silcened and not printed by the Python interpreter.
    iterations_per_full_update: 500      # Non-linear search iterations between every full update, which outputs all visuals and result fits (e.g. model.result, search.summary), this exits the search and can be slow.
    iterations_per_quick_update: 500 #  Non-linear search iterations between every quick update, which just displays the maximum likelihood model fit.
    remove_state_files_at_end: true # Whether to remove the savestate of the seach (e.g. the Emcee hdf5 file) at the end to save hard-disk space (results are still stored as PyAutoFit pickles and loadable).
BFGS:
  search:
    tol: null
  options:
    disp: false
    eps: 1.0e-08
    ftol: 2.220446049250313e-09
    gtol: 1.0e-05
    iprint: -1.0
    maxcor: 10
    maxfun: 15000
    maxiter: 15000
    maxls: 20
  initialize:                       # The method used to generate where walkers are initialized in parameter space {prior | ball}.
    method: ball                    # priors: samples are initialized by randomly drawing from each parameter's prior. ball: samples are initialized by randomly drawing unit values from a narrow uniform distribution.
    ball_lower_limit: 0.49          # The lower limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
    ball_upper_limit: 0.51          # The upper limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
  parallel:
    number_of_cores: 1              # The number of cores the search is parallelized over by default, using Python multiprocessing.
  printing:
    silence: false                  # If True, the default print output of the non-linear search is silcened and not printed by the Python interpreter.
    iterations_per_full_update: 500      # Non-linear search iterations between every full update, which outputs all visuals and result fits (e.g. model.result, search.summary), this exits the search and can be slow.
    iterations_per_quick_update: 500 #  Non-linear search iterations between every quick update, which just displays the maximum likelihood model fit.
    remove_state_files_at_end: true # Whether to remove the savestate of the seach (e.g. the Emcee hdf5 file) at the end to save hard-disk space (results are still stored as PyAutoFit pickles and loadable).
LBFGS:
  search:
    tol: null
  options:
    disp: false
    eps: 1.0e-08
    ftol: 2.220446049250313e-09
    gtol: 1.0e-05
    iprint: -1.0
    maxcor: 10
    maxfun: 15000
    maxiter: 15000
    maxls: 20
  initialize:                       # The method used to generate where walkers are initialized in parameter space {prior | ball}.
    method: ball                    # priors: samples are initialized by randomly drawing from each parameter's prior. ball: samples are initialized by randomly drawing unit values from a narrow uniform distribution.
    ball_lower_limit: 0.49          # The lower limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
    ball_upper_limit: 0.51          # The upper limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
  parallel:
    number_of_cores: 1              # The number of cores the search is parallelized over by default, using Python multiprocessing.
  printing:
    silence: false                  # If True, the default print output of the non-linear search is silcened and not printed by the Python interpreter.
    iterations_per_full_update: 500      # Non-linear search iterations between every full update, which outputs all visuals and result fits (e.g. model.result, search.summary), this exits the search and can be slow.
    iterations_per_quick_update: 500 #  Non-linear search iterations between every quick update, which just displays the maximum likelihood model fit.
    remove_state_files_at_end: true # Whether to remove the savestate of the seach (e.g. the Emcee hdf5 file) at the end to save hard-disk space (results are still stored as PyAutoFit pickles and loadable).
Drawer:
  search:
    total_draws: 50
  initialize:                       # The method used to generate where walkers are initialized in parameter space {prior | ball}.
    method: ball                    # priors: samples are initialized by randomly drawing from each parameter's prior. ball: samples are initialized by randomly drawing unit values from a narrow uniform distribution.
    ball_lower_limit: 0.49          # The lower limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
    ball_upper_limit: 0.51          # The upper limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
  parallel:
    number_of_cores: 1              # The number of cores the search is parallelized over by default, using Python multiprocessing.
  printing:
    silence: false                  # If True, the default print output of the non-linear search is silcened and not printed by the Python interpreter.
    iterations_per_full_update: 500      # Non-linear search iterations between every full update, which outputs all visuals and result fits (e.g. model.result, search.summary), this exits the search and can be slow.
    iterations_per_quick_update: 500 #  Non-linear search iterations between every quick update, which just displays the maximum likelihood model fit.
    remove_state_files_at_end: true # Whether to remove the savestate of the seach (e.g. the Emcee hdf5 file) at the end to save hard-disk space (results are still stored as PyAutoFit pickles and loadable).