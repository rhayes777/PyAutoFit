# Configuration files that customize the default behaviour of non-linear searches.

# **PyAutoFit** supports the following optimizer algorithms:

# - PySwarms: https://github.com/ljvmiranda921/pyswarms / https://pyswarms.readthedocs.io/en/latest/index.html

# Settings in the [search], [run] and [options] entries are specific to each nested algorithm and should be
# determined by consulting that optimizers method's own readthedocs.

PySwarmsGlobal:
  run:
    iters: 2000
  search:
    cognitive: 0.5
    ftol: -.inf
    inertia: 0.9
    n_particles: 50
    social: 0.3
  initialize:                       # The method used to generate where walkers are initialized in parameter space {prior | ball}.
    method: ball                    # priors: samples are initialized by randomly drawing from each parameter's prior. ball: samples are initialized by randomly drawing unit values from a narrow uniform distribution.
    ball_lower_limit: 0.49          # The lower limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
    ball_upper_limit: 0.51          # The upper limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
  parallel:
    number_of_cores: 1              # The number of cores the search is parallelized over by default, using Python multiprocessing.
  printing:
    silence: false                  # If True, the default print output of the non-linear search is silcened and not printed by the Python interpreter.
  updates:
    iterations_per_update: 500      # The number of iterations of the non-linear search performed between every 'update', where an update performs tasks like outputting model.results.
    remove_state_files_at_end: true # Whether to remove the savestate of the seach (e.g. the Emcee hdf5 file) at the end to save hard-disk space (results are still stored as PyAutoFit pickles and loadable).
PySwarmsLocal:
  run:
    iters: 2000
  search:
    cognitive: 0.5
    ftol: -.inf
    inertia: 0.9
    minkowski_p_norm: 2
    n_particles: 50
    number_of_k_neighbors: 3
    social: 0.3
  initialize:                       # The method used to generate where walkers are initialized in parameter space {prior | ball}.
    method: ball                    # priors: samples are initialized by randomly drawing from each parameter's prior. ball: samples are initialized by randomly drawing unit values from a narrow uniform distribution.
    ball_lower_limit: 0.49          # The lower limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
    ball_upper_limit: 0.51          # The upper limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
  parallel:
    number_of_cores: 1              # The number of cores the search is parallelized over by default, using Python multiprocessing.
  printing:
    silence: false                  # If True, the default print output of the non-linear search is silcened and not printed by the Python interpreter.
  updates:
    iterations_per_update: 500      # The number of iterations of the non-linear search performed between every 'update', where an update performs tasks like outputting model.results.
    remove_state_files_at_end: true # Whether to remove the savestate of the seach (e.g. the Emcee hdf5 file) at the end to save hard-disk space (results are still stored as PyAutoFit pickles and loadable).
LBFGS:
  search:
    tol: null
  options:
    disp: false
    eps: 1.0e-08
    ftol: 2.220446049250313e-09
    gtol: 1.0e-05
    iprint: -1.0
    maxcor: 10
    maxfun: 15000
    maxiter: 15000
    maxls: 20
  initialize:                       # The method used to generate where walkers are initialized in parameter space {prior | ball}.
    method: ball                    # priors: samples are initialized by randomly drawing from each parameter's prior. ball: samples are initialized by randomly drawing unit values from a narrow uniform distribution.
    ball_lower_limit: 0.49          # The lower limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
    ball_upper_limit: 0.51          # The upper limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
  parallel:
    number_of_cores: 1              # The number of cores the search is parallelized over by default, using Python multiprocessing.
  printing:
    silence: false                  # If True, the default print output of the non-linear search is silcened and not printed by the Python interpreter.
  updates:
    iterations_per_update: 500      # The number of iterations of the non-linear search performed between every 'update', where an update performs tasks like outputting model.results.
    remove_state_files_at_end: true # Whether to remove the savestate of the seach (e.g. the Emcee hdf5 file) at the end to save hard-disk space (results are still stored as PyAutoFit pickles and loadable).
Drawer:
  search:
    total_draws: 50
  initialize:                       # The method used to generate where walkers are initialized in parameter space {prior | ball}.
    method: ball                    # priors: samples are initialized by randomly drawing from each parameter's prior. ball: samples are initialized by randomly drawing unit values from a narrow uniform distribution.
    ball_lower_limit: 0.49          # The lower limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
    ball_upper_limit: 0.51          # The upper limit of the uniform distribution unit values are drawn from when initializing walkers using the ball method.
  parallel:
    number_of_cores: 1              # The number of cores the search is parallelized over by default, using Python multiprocessing.
  printing:
    silence: false                  # If True, the default print output of the non-linear search is silcened and not printed by the Python interpreter.
  updates:
    iterations_per_update: 500      # The number of iterations of the non-linear search performed between every 'update', where an update performs tasks like outputting model.results.
    remove_state_files_at_end: true # Whether to remove the savestate of the seach (e.g. the Emcee hdf5 file) at the end to save hard-disk space (results are still stored as PyAutoFit pickles and loadable).