{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#%%\n",
        "\"\"\"\n",
        "Tutorial 4: Source Code\n",
        "=======================\n",
        "\n",
        "Up to now, all tutorials have been self contained. That is, the code used to define the model, analysis, run the\n",
        "non-linear search, load data and plot images were contained in the Jupyter notebooks or Python scritps you were run.\n",
        "\n",
        "For a real software developmet project, this code woulnd't be contained in one script, but instead make up the\n",
        "project's source code. In this tutorial, and every tutorial hereafter, we will set up our code as if it were\n",
        "an actual software project with a clearly defined source code library. This source code can be found in the folder\n",
        "'/autofit_workspace/howtofit/chapter_1_introduction/tutorial_4_source_code/src'.\n",
        "\n",
        "Check it out, and first note the directory structure of the source code, which is separated into 5 packages: 'dataset',\n",
        "'fit', 'model', 'plot' and 'phase'. This cleanly separates the different parts of the code which perform do different\n",
        "tasks and I recommend your model-fitting project close adopts this structure!\n",
        "\n",
        "For example, the code which handles the model is completely separate from the code which handles the analysis class.\n",
        "The model thus never interfaces directly with PyAutoFit, ensuring good code design by removing dependencies between\n",
        "parts of the code that do not need them! Its the same for the part of the code that stores data ('dataset')\n",
        "and fits a model to a dataset ('fit') - by keeping them separate its clear which part of the code do what task.\n",
        "\n",
        "This is a principle aspect of object oriented design and software engineering called 'separation of concerns' and all\n",
        "templates we provide in the HowToFit series will adhere to it.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from autoconf import conf\n",
        "import autofit as af\n",
        "from pyprojroot import here\n",
        "\n",
        "workspace_path = str(here())\n",
        "print(\"Workspace Path: \", workspace_path)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf.instance = conf.Config(\n",
        "    config_path=f\"{workspace_path}/howtofit/config\",\n",
        "    output_path=f\"{workspace_path}/howtofit/output\",  # <- This sets up where the non-linear search's outputs go.\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, checkout the file \n",
        "\n",
        " 'autofit_workspace/howtofit/chapter_1_introduction/tutorial_4_source_code/src/__init__.py\n",
        "\n",
        "Here, we have added imports to this file allowing us to import the entire project in one go, which we do below,\n",
        "importing it as 'htf'. \n",
        "\n",
        "Many software projects tend not to do this, instead relying on the user explicitly importing every module in the \n",
        "project that need, for example:\n",
        "\n",
        "   from tutorial_4_source_code.src.dataset.dataset import Dataset\n",
        "   from tutorial_4_source_code.src.model.gaussian import Gaussian\n",
        "   from tutorial_4_source_code.src.plot import dataset_plots\n",
        "   from tutorial_4_source_code.src.plot import fit_plots\n",
        "\n",
        "Clearly, this creates a burden on the user in them having to understand the project structure and a lot of unecessary\n",
        "code that clutters their scripts! Furthermore, as you'll see below, by controlling the project import in this way\n",
        "you can design an API that makes takes like plotting results more intuitive.\n",
        "\"\"\"\n",
        "\n",
        "from howtofit.chapter_1_introduction.tutorial_4_source_code import (\n",
        "    src as htf,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin, in the 'src' folder checkout the 'data' package, which contains one module, 'dataset.py'. Whereas before we \n",
        "had arrays which separately contained the data and noise_map, from here on we'll combine them into a 'Dataset' class, \n",
        "which can be easily extended if our model-fitting problem has additional data components.\n",
        "\n",
        "To create the Dataset, we import the simulator module and use it to generate the Dataset's data and noise-map. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from howtofit.simulators.chapter_1 import gaussian_x1\n",
        "\n",
        "dataset = htf.Dataset(data=gaussian_x1.data, noise_map=gaussian_x1.noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Previously, we manually specified how to plot the dataset. These plotting functions are now in our source code, in the\n",
        "'plot' package - check them out now! You'll note we have separate modules for plotting lines (e.g. anything which is \n",
        "line, the data, a residual-map, etc.), parts of the dataset or the results of a fit.\n",
        "\n",
        "You should take note of two things:  \n",
        "\n",
        " - The dataset plot functions take instances of the Dataset class, meaning we we don't have to manually the part of \n",
        " our data we want to pass to the function, making for a more concise API.\n",
        " \n",
        " - In plot/__init__.py we have imported the 'dataset_plots', 'fit_plots' and 'line_plots' modules as their \n",
        " corresponding class names; 'Dataset', 'FitDataset' and 'Line'. This again makes for a clean API, where it is \n",
        " immediately obvious to the user how to plot the objects they have used elsewhere in the project for performing \n",
        " calculations.\n",
        "\n",
        "Lets use a plot function to plot our data.\n",
        "\"\"\"\n",
        "\n",
        "htf.plot.Dataset.data(dataset=dataset)\n",
        "htf.plot.Dataset.noise_map(dataset=dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, look at the 'model' package, which contains the module 'gaussian.py'. This contains the Gaussian class we have\n",
        "used previous to compose the 1D Gaussian model that we fit.\n",
        "\n",
        "By packaging all the model components into a single package, this will make it straight forward to add new model\n",
        "components to the source code.\n",
        "\"\"\"\n",
        "\n",
        "gaussian = htf.Gaussian(centre=50.0, intensity=2.0, sigma=20.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, lets checkout the 'fit' package which contains the 'fit.py' module. This packages all the fitting methods we \n",
        "introduced in tutorial 2 into a single FitDataset class, making it straight forward to compute the residual-map, \n",
        "chi-squared map, log likelihood and so forth. \n",
        "\n",
        "Again, take note of how the fit plot functions take an instance of the FitDataset class and were imported as \n",
        "'FitDataset', making for a clean API where it is intuitive how to plot the fit.\n",
        "\n",
        "Below, I used the Gaussian model above to illustrate how we can easily plot different aspects of a fit. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_data = gaussian.profile_from_xvalues(xvalues=dataset.xvalues)\n",
        "\n",
        "fit = htf.FitDataset(dataset=dataset, model_data=model_data)\n",
        "\n",
        "htf.plot.FitDataset.residual_map(fit=fit)\n",
        "htf.plot.FitDataset.normalized_residual_map(fit=fit)\n",
        "htf.plot.FitDataset.chi_squared_map(fit=fit)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we discussed in tutorial 2, the different steps of performing a fit (e.g. computing the residuals, the chi-squared,\n",
        "log likelihood, and so forth) are pretty much generic tasks performed by any model-fitting problem. \n",
        "\n",
        "Thus, you should literally be able to copy and paste the FitDataset class found in this tutorial (and future tutorials) \n",
        "and use them in your modeling software! I have made sure the class works for datasets of higher dimensionality (e.g. \n",
        "2D images or 3D datacubes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We're finally ready to look at how our source code sets up the non-linear search and model-fit. Whereas before, we \n",
        "manually set up the model, analysis and non-linear search, from now on we're going to use PyAutoFits 'phase API' which\n",
        "uses the 'phase' package, which contains 3 modules: 'phase.py', 'analysis.py' and 'result.py'.\n",
        "\n",
        "At this point, you should open and inspect (in detail) these 3 source code files. These are the heart of any PyAutoFit \n",
        "model fit! \n",
        "\n",
        "An over view of each is as follows:\n",
        "\n",
        "phase.py -> contains the Phase class:\n",
        "\n",
        "    - Receives the model to be fitted (in this case a single Gaussian).\n",
        "    - Handles the directory structure of the output (in this example results are output to the folder\n",
        "      '/output/phase_example/'.\n",
        "    - Is passed the data when run, which is set up for the analysis.\n",
        "\n",
        "analysis.py -> contains the Analysis class (is a restructred version of the the previous tutorial's Analysis class):\n",
        "\n",
        "    - Prepares the dataset for fitting.\n",
        "    - Fits this dataset with a model instance to compute a log likelihood for every iteration of the non-linear search.\n",
        "\n",
        "result.py -> contains the Result class:\n",
        "\n",
        "    - Stores the Samples object containing information on the non-linear search's samples.\n",
        "    - Has functions to create the model image, residual-map, chi-squared-map and so forth of the maximum log likelihood \n",
        "      model etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform a non-linear search in PyAutoFit now only requires that we instantiate and run a Phase object. The Phase \n",
        "performs the following tasks (which we performed manually in the previous tutorial):\n",
        "\n",
        "    - Builds the model to be fitted and interfaces it with the non-linear search algorithm.\n",
        "    - Receives the data to be fitted and prepares it so the model can fit it.\n",
        "    - Contains the Analysis class that defines the log likelihood function.\n",
        "    - Returns the results. including the non-linear search's samples and the maximum likelihood fit.\n",
        "\n",
        "In the previous tutorial, after we composed our model using the _PriorModel_ object we had to manually specify its\n",
        "priors. However, now we are using a source code, the priors are instead loaded from config files, specifically the\n",
        "config file found at 'autofit_workspace/howtofit/config/json_piors/gaussian.json'. If you inspect this file, you'll \n",
        "see the priors are set up using the same values as the previous tutorial.\n",
        "\n",
        "It is worth noting that the name of this config file, 'gaussian.json', is not a conincedence. It is named after the\n",
        "module we imported to create the _PriorModel_, the 'gaussian.py' module. Thus, our the json_config files we use to\n",
        "set up the default priors of different model components share the name of the module they are in! \n",
        "\n",
        "Although we don't in this tutorial, we could of course over write the priors with new priors as we did in the previous\n",
        "tutorial.\n",
        "\n",
        "Lets instantiate and run a phase, which reduces the task of performing a model-fit in PyAutoFit to just two lines. \n",
        "The results are output to the path 'autofit_workspace/howtofit/chapter_1_introduction/output/phase_t4/emcee', which in \n",
        "contrast to the previous tutorial includes the phase name in the path structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "phase = htf.Phase(\n",
        "    phase_name=\"phase_t4\", gaussian=af.PriorModel(htf.Gaussian), search=af.Emcee()\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Emcee has begun running - checkout the autofit_workspace/howtofit/chapter_1_introduction/output/phase_t4/emcee\"\n",
        "    \"folder for live output of the results.\"\n",
        "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
        ")\n",
        "\n",
        "result = phase.run(dataset=dataset)\n",
        "\n",
        "print(\"Emcee has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The phase returns a Result object, just like the model-fit performed in the previous tutorial did. However, in\n",
        "'result.py' you'll have noted we extended the Results object to include a property containing an instance of the \n",
        "maximum likelihood fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_fit)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another benefit of writing our plot functions so that their input is instances of class they plot is now clear. We can \n",
        "visualize our results by simply passing the instance which is readily available in the results to our plot functions!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "htf.plot.FitDataset.model_data(fit=result.max_log_likelihood_fit)\n",
        "htf.plot.FitDataset.residual_map(fit=result.max_log_likelihood_fit)\n",
        "htf.plot.FitDataset.chi_squared_map(fit=result.max_log_likelihood_fit)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And with that, we have introduced the PyAutoFit phase API alongside an example project, which provides a template on\n",
        "how to structure model-fitting software. \n",
        "\n",
        "All of the remaining tutorials will be provided with a 'src' source code folder, which we will add to the __init__.py\n",
        "file of in order to design the API of our project. \n",
        "\n",
        "The functionality these tutorials describe will be reflected in the comments of the source code. At this point, you \n",
        "should be thinking about how you might wish to structure your model-fitting software!"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}