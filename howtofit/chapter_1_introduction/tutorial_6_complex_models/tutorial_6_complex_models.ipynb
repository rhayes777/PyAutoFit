{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 6: Complex Models\n",
        "==========================\n",
        "\n",
        "Up to now, we've fitted a very simple model - a single 1D _Gaussian_ with just 3 free parameters. In this tutorial,\n",
        "we'll look at how PyAutoFit allows us to compose and fit models of arbitrary complexity.\n",
        "\n",
        "To begin, you should check out the module 'tutorial_6_complex_models/model/profiles.py'. In previous tutorials this\n",
        "module was called 'gaussian.py' and it contained only the _Gaussian_ class we fitted to data. The module now includes\n",
        "a second profile, 'Exponential', which like the _Gaussian_ class is a model-component that can be fitted to data.\n",
        "\n",
        "Up to now, our data has always been generated using a single _Gaussian_ profile. Thus, we have only needed to fit\n",
        "it with a single Gaussian. In this tutorial, our _Dataset_ is now a superpositions of multiple profiles (e.g a\n",
        "Gaussians + Exponential). The models we compose and fit are therefore composed of multiple profiles, such that when we\n",
        "generate the model-data we generate it as the sum of all individual profiles in our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from autoconf import conf\n",
        "import autofit as af\n",
        "from autofit_workspace.howtofit.chapter_1_introduction.tutorial_6_complex_models import (\n",
        "    src as htf,\n",
        ")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "workspace_path = os.environ[\"WORKSPACE\"]\n",
        "print(\"Workspace Path: \", workspace_path)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup the configs as we did in the previous tutorial, as well as the output folder for our non-linear search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf.instance = conf.Config(\n",
        "    config_path=f\"{workspace_path}/howtofit/config\",\n",
        "    output_path=f\"{workspace_path}/howtofit/output/chapter_1\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets quickly recap tutorial 1, where using PriorModels we created a _Gaussian_ as a model component and used it to map a\n",
        "list of parameters to a model instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.PriorModel(htf.profiles.Gaussian)\n",
        "\n",
        "print(\"PriorModel _Gaussian_ object: \\n\")\n",
        "print(model)\n",
        "\n",
        "instance = model.instance_from_vector(vector=[0.1, 0.2, 0.3])\n",
        "\n",
        "print(\"Model Instance: \\n\")\n",
        "print(instance)\n",
        "\n",
        "print(\"Instance Parameters \\n\")\n",
        "print(\"x = \", instance.centre)\n",
        "print(\"intensity = \", instance.intensity)\n",
        "print(\"sigma = \", instance.sigma)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining a model using multiple model components is straight forward in PyAutoFit, using a CollectionPriorModel\n",
        "object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.CollectionPriorModel(\n",
        "    gaussian=htf.profiles.Gaussian, exponential=htf.profiles.Exponential\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A CollectionPriorModel behaves like a _PriorModel_ but contains a collection of model components. For example, it can\n",
        "create a model instance by mapping a list of parameters, which in this case is 6 (3 for the _Gaussian_ [centre,\n",
        "intensity, sigma] and 3 for the Exponential [centre, intensity, rate])."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instance = model.instance_from_vector(vector=[0.1, 0.2, 0.3, 0.4, 0.5, 0.01])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This instance contains each of the model components we defined above, using the input argument name of the\n",
        "CollectionoPriorModel to define the attributes in the instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Instance Parameters \\n\")\n",
        "print(\"x (Gaussian) = \", instance.gaussian.centre)\n",
        "print(\"intensity (Gaussian) = \", instance.gaussian.intensity)\n",
        "print(\"sigma (Gaussian) = \", instance.gaussian.sigma)\n",
        "print(\"x (Exponential) = \", instance.exponential.centre)\n",
        "print(\"intensity (Exponential) = \", instance.exponential.intensity)\n",
        "print(\"sigma (Exponential) = \", instance.exponential.rate)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can call the components of a CollectionPriorModel whatever we want, and the mapped instance will use those names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_custom_names = af.CollectionPriorModel(\n",
        "    james=htf.profiles.Gaussian, rich=htf.profiles.Exponential\n",
        ")\n",
        "\n",
        "instance = model_custom_names.instance_from_vector(\n",
        "    vector=[0.1, 0.2, 0.3, 0.4, 0.5, 0.01]\n",
        ")\n",
        "\n",
        "print(\"Instance Parameters \\n\")\n",
        "print(\"x (Gaussian) = \", instance.james.centre)\n",
        "print(\"intensity (Gaussian) = \", instance.james.intensity)\n",
        "print(\"sigma (Gaussian) = \", instance.james.sigma)\n",
        "print(\"x (Exponential) = \", instance.rich.centre)\n",
        "print(\"intensity (Exponential) = \", instance.rich.intensity)\n",
        "print(\"sigma (Exponential) = \", instance.rich.rate)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can create a model composed of multiple components, lets fit it to a _Dataset_. To do this, we updated this \n",
        "tutorial's phase package, spefically its 'Analysis' class such that it creates model data as a super position of all of \n",
        "the model's individual profiles. For example, in the model above, the model data is the sum of the Gaussian's \n",
        "individual profile and Exponential's individual profile.\n",
        "\n",
        "Checkout 'phase.py' and 'analysis.py' now, for a description of how this has been implemented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the simulator module and set up the _Dataset_. This uses a new _Dataset_ that is generated as a sum of a _Gaussian_ \n",
        "and Exponential profile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autofit_workspace.howtofit.simulators.chapter_1 import gaussian_x1_exponential_x1\n",
        "\n",
        "dataset = htf.Dataset(\n",
        "    data=gaussian_x1_exponential_x1.data, noise_map=gaussian_x1_exponential_x1.noise_map\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We again need to create a mask for our data. In this exmample, we'll omit actual masking of the dataset, but still\n",
        "need to define a mask to pass the 'phase.run' method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = np.full(fill_value=False, shape=dataset.data.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets now perform the fit using our model which is composed of two profiles. You'll note that the Emcee\n",
        "dimensionality has increased from N=3 to N=6, given that we are now fitting two profiles each with 3 free parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "phase = htf.Phase(\n",
        "    phase_name=\"phase_t6_gaussian_x1_exponential_x1\",\n",
        "    profiles=af.CollectionPriorModel(\n",
        "        gaussian=htf.profiles.Gaussian, exponential=htf.profiles.Exponential\n",
        "    ),\n",
        "    search=af.Emcee(),\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Emcee has begun running - checkout the autofit_workspace/howtofit/chapter_1_introduction/output/phase_t5_gaussian_x1_exponential_x1\"\n",
        "    \"folder for live output of the results.\"\n",
        "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
        ")\n",
        "\n",
        "phase.run(dataset=dataset, mask=mask)\n",
        "\n",
        "print(\"Emcee has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quickly inspect the results of this fit, which you may have noticed takes a bit longer to run than the fits performed\n",
        "in previous tutorials. This is because the dimensionality of the model we are fitted increased from 3 to 6.\n",
        "\n",
        "With the CollectionPriorModel, PyAutoFit gives us all the tools we need to compose and fit any model imaginable!\n",
        "Lets fit a model composed of two Gaussians and and an Exponential, which will have a dimensionality of N=9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autofit_workspace.howtofit.simulators.chapter_1 import gaussian_x2_exponential_x1\n",
        "\n",
        "dataset = htf.Dataset(\n",
        "    data=gaussian_x2_exponential_x1.data, noise_map=gaussian_x2_exponential_x1.noise_map\n",
        ")\n",
        "\n",
        "phase = htf.Phase(\n",
        "    phase_name=\"phase_t6_gaussian_x2_exponential_x1\",\n",
        "    profiles=af.CollectionPriorModel(\n",
        "        gaussian_0=htf.profiles.Gaussian,\n",
        "        gaussian_1=htf.profiles.Gaussian,\n",
        "        exponential=htf.profiles.Exponential,\n",
        "    ),\n",
        "    search=af.Emcee(),\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"Emcee has begun running - checkout the autofit_workspace/howtofit/chapter_1_introduction/output/phase_t5_gaussian_x2_exponential_x1\"\n",
        "    \"folder for live output of the results.\"\n",
        "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
        ")\n",
        "\n",
        "phase.run(dataset=dataset, mask=mask)\n",
        "\n",
        "print(\"Emcee has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can fully custommize the model that we fit. Lets suppose we have a _Dataset_ that consists of three _Gaussian_ line\n",
        "profiles, but we also know the following information about the dataset:\n",
        "\n",
        "- All 3 Gaussians are centrally aligned.\n",
        "- The sigma of one _Gaussian_ is equal to 1.0.\n",
        "\n",
        "We can edit our CollectionPriorModel to meet these constraints accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = af.CollectionPriorModel(\n",
        "    gaussian_0=htf.profiles.Gaussian,\n",
        "    gaussian_1=htf.profiles.Gaussian,\n",
        "    gaussian_2=htf.profiles.Gaussian,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This aligns the centres of the 3 Gaussians, reducing the dimensionality of the model from N=9 to N=7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.gaussian_0.centre = model.gaussian_1.centre\n",
        "model.gaussian_1.centre = model.gaussian_2.centre"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This fixes the sigma value of one _Gaussian_ to 1.0, further reducing the dimensionality from N=7 to N=6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.gaussian_0.sigma = 1.0"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now fit this model using a phase as per usual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autofit_workspace.howtofit.simulators.chapter_1 import gaussian_x3\n",
        "\n",
        "dataset = htf.Dataset(data=gaussian_x3.data, noise_map=gaussian_x3.noise_map)\n",
        "\n",
        "phase = htf.Phase(phase_name=\"phase_t6_gaussian_x3\", profiles=model, search=af.Emcee())\n",
        "\n",
        "print(\n",
        "    \"Emcee has begun running - checkout the autofit_workspace/howtofit/chapter_1_introduction/output/phase_t5_gaussian_x3\"\n",
        "    \"folder for live output of the results.\"\n",
        "    \"This Jupyter notebook cell with progress once Emcee has completed - this could take a few minutes!\"\n",
        ")\n",
        "\n",
        "phase.run(dataset=dataset, mask=mask)\n",
        "\n",
        "print(\"Emcee has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And with that, we are complete. In this tutorial, we learned how to compose complex models in PyAutoFit and adjust our\n",
        "'phase.py' and 'analyis.py' modules to fit them. To end, you should think again in more detail about your model\n",
        "fitting problem:\n",
        "\n",
        "Are there many different model components you may wish to define and fit?\n",
        "Is your model-data the super position of many different model components, like the profiles in this tutorial?\n",
        "\n",
        "In this tutorial, all components of our model did the same thing - represent a 'line' of data. In your model, you may\n",
        "have model components that represent different parts of your model, which need to be combined in more complicated ways\n",
        "in order to create your model-fit. In such circumstances, the 'fit' method in your 'Analysis' class may be significantly\n",
        "more complex than the example shown in this tutorial. Nevertheless, you now have all the tools you need to define,\n",
        "compose and fit very complex models - there isn't much left for you to learn on your journey through PyAutoFit!"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}