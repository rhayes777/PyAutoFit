{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 10: Data and Models\n",
        "===========================\n",
        "\n",
        "Up to now, we've used used the `Aggregator` to load and inspect the `Samples` of 3 model-fits.\n",
        "\n",
        "In this tutorial, we'll look at how the way we designed our source code makes it easy to use the `Aggregator` to\n",
        "inspect, interpret and plot the results of the model-fit, including refitting the best models to our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from pyprojroot import here\n",
        "\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To load these results with the `Aggregator`, we again point it to the path of the results we want it to inspect, with\n",
        "our path straight to the `Aggregator` results ensuring we don't need to filter our `Aggregator` in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg = af.Aggregator(\n",
        "    directory=path.join(\"output\", \"howtofit\", \"chapter_1\", \"aggregator\")\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll reuse the `plot_line` function of previous tutorials, however it now displays to the notebook as opposed to\n",
        "outputting the results to a .png file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_line(xvalues, line, title=None, ylabel=None, errors=None, color=\"k\"):\n",
        "    plt.errorbar(\n",
        "        x=xvalues, y=line, yerr=errors, color=color, ecolor=\"k\", elinewidth=1, capsize=2\n",
        "    )\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"x value of profile\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.show()\n",
        "    plt.clf()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use the `Aggregator` to load a generator of every fit`s data, by changing the `output` attribute to the \n",
        "`data` attribute at the end of the aggregator.\n",
        "\n",
        "Note that in the `Analysis` class of tutorial 7, we specified that the `data` object would be saved to hard-disc using\n",
        "the `save_attributes_for_aggregator` method, so that the `Aggregator` can load it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_gen = agg.values(\"data\")\n",
        "print(\"Datas:\")\n",
        "print(list(data_gen), \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot the `data` using the `plot_line` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for data in agg.values(\"data\"):\n",
        "    plot_line(\n",
        "        xvalues=np.arange(data.shape[0]),\n",
        "        line=data,\n",
        "        title=\"Data\",\n",
        "        ylabel=\"Data Values\",\n",
        "        color=\"k\",\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` dictionary we input into the `NonLinearSearch` is also available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for info in agg.values(\"info\"):\n",
        "    print(info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can repeat the same trick to get the `noise_map` of every fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "noise_map_gen = agg.values(\"noise_map\")\n",
        "print(\"Masks:\")\n",
        "print(list(noise_map_gen), \"\\n\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We're going to refit each dataset with the `max_log_likelihood_instance` of each model-fit and plot the residuals.\n",
        "\n",
        "(If you are unsure what the `zip` is doing below, it essentially combines the `data_gen`, `noise_map_gen` and\n",
        " `samples_gen` into one list such that we can iterate over them simultaneously)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples_gen = agg.values(\"samples\")\n",
        "data_gen = agg.values(\"data\")\n",
        "noise_map_gen = agg.values(\"noise_map\")\n",
        "\n",
        "for data, noise_map, samples in zip(data_gen, noise_map_gen, samples_gen):\n",
        "\n",
        "    instance = samples.max_log_likelihood_instance\n",
        "\n",
        "    xvalues = np.arange(data.shape[0])\n",
        "\n",
        "    model_data = sum(\n",
        "        [profile.profile_from_xvalues(xvalues=xvalues) for profile in instance]\n",
        "    )\n",
        "\n",
        "    residual_map = data - model_data\n",
        "\n",
        "    plot_line(\n",
        "        xvalues=xvalues,\n",
        "        line=residual_map,\n",
        "        title=\"Residual Map\",\n",
        "        ylabel=\"Residuals\",\n",
        "        color=\"k\",\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is a problem with how we plotted the residuals above, can you guess what it is?\n",
        "\n",
        "We used lists! If we had fit a large sample of data, the above object would store the data of all objects simultaneously \n",
        "in memory on our hard-disk, likely crashing our laptop! To avoid this, we must write functions that manipulate the \n",
        "`Aggregator` generators as generators themselves. Below is an example function that performs the same task as above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_residuals_from_agg_obj(agg_obj):\n",
        "\n",
        "    data = agg_obj.data\n",
        "    noise_map = agg_obj.noise_map\n",
        "    samples = agg_obj.samples\n",
        "\n",
        "    instance = samples.max_log_likelihood_instance\n",
        "\n",
        "    xvalues = np.arange(data.shape[0])\n",
        "\n",
        "    model_data = sum(\n",
        "        [profile.profile_from_xvalues(xvalues=xvalues) for profile in instance]\n",
        "    )\n",
        "\n",
        "    residual_map = data - model_data\n",
        "\n",
        "    plot_line(\n",
        "        xvalues=xvalues,\n",
        "        line=residual_map,\n",
        "        title=\"Residual Map\",\n",
        "        ylabel=\"Residuals\",\n",
        "        color=\"k\",\n",
        "    )\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To manipulate this function as a generator using the `Aggregator`, we apply it to the `Aggregator`'s `map` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot_residuals_gen = agg.map(func=plot_residuals_from_agg_obj)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets get the `max_log_likelihood_instance`s, as we did in tutorial 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "instances = [samps.max_log_likelihood_instance for samps in agg.values(\"samples\")]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Okay, we want to inspect the fit of each `max_log_likelihood_instance`. To do this, we reperform each fit.\n",
        "\n",
        "First, we need to create the `model_data` of every `max_log_likelihood_instance`. Lets begin by creating a list \n",
        "of profiles of every phase."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}